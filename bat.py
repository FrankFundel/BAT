# -*- coding: utf-8 -*-
"""BAT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u_JHRkgzIM0anxOMMuHUOLKw3SHu86e8

# Bat Call Classification using Transformer Networks

We will use ultrasound recordings from 5 european bat species to train a custom deep learning transformer network. The special things about our model is that we train it on interlaced tiles of spectrogram sequences to obtain unraveled classification sequences which should be robust to multi-species recordings.

To accomplish this, we follow those steps:
1. Data collection
2. Data framing
3. Model building
4. Optimization
5. Evaluation
6. Implementation

![](https://drive.google.com/uc?export=view&id=1THTxoMa1fql1F4JDMeAcrACEFO2T7ldp)

# The dataset

So first we collect our data. The requirements for our dataset should be:
- Only one bat calling at a time
- Verified classification
- As little noise as possible
- High variability
- Even distribution

We could not get the dataset from our university in time, but we got access to the largest european bat call dataset there is, the Skiba dataset (Skiba, 1932-2013) from the "Museum f√ºr Naturkunde Berlin" (www.tierstimmenarchiv.de) with over 1500 recordings and over 45000 single calls. We have over 10GB of WAV audio and a CSV containing some useful information, but the most important ones for now are **filename** and **species**.
"""

#from google.colab import drive 
#drive.mount('/content/drive')
base = ""

import pandas as pd 
df = pd.read_csv(base + 'data.csv')
print(df)

"""Let's have a look at the class distribution. We have the following classes (species):"""

classes = {
  "Rhinolophus ferrumequinum": 0,
  "Rhinolophus hipposideros": 1,
  "Myotis daubentonii": 2,
  "Myotis brandtii": 3,
  "Myotis mystacinus": 4,
  "Myotis emarginatus": 5,
  "Myotis nattereri": 6,
  "Myotis bechsteinii": 7,
  "Myotis myotis": 8,
  "Nyctalus noctula": 9,
  "Nyctalus leisleri": 10,
  "Nyctalus lasiopterus": 11,
  "Pipistrellus pipistrellus": 12,
  "Pipistrellus pygmaeus": 13,
  "Pipistrellus nathusii": 14,
  "Pipistrellus kuhlii": 15,
  "Hypsugo savii": 16,
  "Vespertilio murinus": 17,
  "Eptesicus serotinus": 18,
  "Eptesicus nilssonii": 19,
  "Plecotus auritus": 20,
  "Plecotus austriacus": 21,
  "Barbastella barbastellus": 22,
  "Tadarida teniotis": 23,
  "Miniopterus schreibersii": 24,
  "Myotis capaccinii": 25,
  "Myotis dasycneme": 26,
  "Pipistrellus maderensis": 27,
  "Rhinolophus blasii": 28
}

class_list = list(classes)

import matplotlib.pyplot as plt
import numpy as np

print(df["species"].value_counts())
#df["species"].value_counts().plot(kind='barh', figsize=(10, 10))

"""We can see that our dataset is not really evenly distributed, mainly because some species are rarer than others. But let's have a look at an individual recording :) They are all recorded with the same device "Pettersson D980 Time expansion. copy to Sony WM D6C" and with the same time expansion of 1:10, sample rate of 96000 and bit depth of 24."""

import librosa
import librosa.display

def plot_signal(y, sr, title):
  D = librosa.stft(y)
  S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

  fig, ax = plt.subplots(figsize=(10, 5), nrows=2, sharex=True)
  fig.tight_layout(pad=3.0)

  img1 = librosa.display.waveshow(y, sr=sr, ax=ax[0])
  ax[0].set(title=title + " - Waveform")

  img2 = librosa.display.specshow(S_db, x_axis='time', y_axis='linear', ax=ax[1])
  ax[1].set(title=title + " - Spectrogram")

example_audio = base + 'data/' + class_list[19] + ".wav"
example_y, example_sr = librosa.load(example_audio, duration=10)
example_species = class_list[19]
plot_signal(example_y, example_sr, example_species)

"""In the waveform we can clearly see the peaks where the calls happen and the noise in the background. The Nordfledermaus(Eptesicus nilssonii) calls are highly frequency modulated and around 24-27 kHZ, what we can both see in the spectrogram. Not that because auf the time expansion, we need to x10 the frequency, so 2500Hz is 25000Hz = 25kHz

**Eptesicus nilssoni**

![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Eptesicus_nilssonii_hibernating.JPG/300px-Eptesicus_nilssonii_hibernating.JPG)

You can also give it a listen if you want:
"""

import IPython.display as ipd
ipd.Audio(example_y, rate=example_sr)

"""# Preparing the data

Before building a model and training, we need to prepare our data. First we try to reduce the noise by using a 10th order butterworth high-pass filter with a cut-off frequency at 15kHz. We chose 15kHz, because there are not bat calls at or below 15kHz.
"""

from scipy import signal

b, a = signal.butter(10, 15000, 'highpass', analog=True)
w, h = signal.freqs(b, a)
plt.semilogx(w, 20 * np.log10(abs(h)))
plt.title('Butterworth filter frequency response')
plt.xlabel('Frequency [radians / second]')
plt.ylabel('Amplitude [dB]')
plt.margins(0, 0.1)
plt.grid(which='both', axis='both')
plt.axvline(15000, color='green') # cutoff frequency
plt.show()

b, a = signal.butter(10, 15000 / 120000, 'highpass')
example_filtered = signal.lfilter(b, a, example_y)
plot_signal(example_filtered, example_sr, "Filtered")

"""In the waveform we can already see a quite good noise reduction. We could also do a peak detection:"""

onset_env = librosa.onset.onset_strength(y=example_filtered, sr=example_sr, hop_length=512, aggregate=np.max)
peaks = librosa.util.peak_pick(onset_env, 3, 3, 3, 3, 10, 5)
times = librosa.times_like(onset_env, sr=example_sr, hop_length=512)

fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(10, 5))

D = librosa.stft(example_filtered)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

def denoise(x):
  return np.abs(x - x.mean())

spectrogram = np.apply_along_axis(denoise, axis=1, arr=S_db)

ax[0].plot(times, onset_env, alpha=0.8, label='Onset strength')
ax[0].vlines(times[peaks], 0, onset_env.max(), color='r', alpha=0.8, label='Selected peaks')
ax[0].legend(frameon=True, framealpha=0.8)
ax[0].label_outer()

librosa.display.specshow(spectrogram, x_axis='time', ax=ax[1])

"""We are no ready to create our training data. For that let's focus on the 11 biggest classes:"""

classes13 = {
  "Pipistrellus pipistrellus": 0,
  "Pipistrellus nathusii": 1,
  "Pipistrellus kuhlii": 2,
  "Myotis daubentonii": 3,
  "Nyctalus noctula": 4,
  "Nyctalus leisleri": 5,
  "Eptesicus serotinus": 6,
  "Myotis dasycneme": 7,
  "Miniopterus schreibersii": 8,
  "Vespertilio murinus": 9,
  "Rhinolophus ferrumequinum": 10,
  "Myotis emarginatus": 11,
  "Myotis myotis": 12,
}

classes23 = {
  "Pipistrellus pipistrellus": 0,
  "Pipistrellus nathusii": 1,
  "Pipistrellus kuhlii": 2,
  "Myotis daubentonii": 3,
  "Nyctalus noctula": 4,
  "Nyctalus leisleri": 5,
  "Myotis nattereri": 6,
  "Eptesicus serotinus": 7,
  "Myotis dasycneme": 8,
  "Miniopterus schreibersii": 9,
  "Vespertilio murinus": 10,
  "Rhinolophus ferrumequinum": 11,
  "Rhinolophus hipposideros": 12,
  "Myotis brandtii": 13,
  "Myotis mystacinus": 14,
  "Myotis emarginatus": 15,
  "Myotis myotis": 16,
  "Pipistrellus pygmaeus": 17,
  "Hypsugo savii": 18,
  "Eptesicus nilssonii": 19,
  "Tadarida teniotis": 20,
  "Myotis capaccinii": 21,
  "Pipistrellus maderensis": 22,
  "Rhinolophus blasii": 23
}

labels = classes13

"""We create a train, test, validation split with the 1500 recordings locally. Filtered, de-noised, windowed, split and stored in HDF5."""

from keras.utils.np_utils import to_categorical  
from tqdm import tqdm
import cv2

def slideWindow(a, size, step):
  b = []
  i = 0
  pos = 0
  while pos + size < len(a):
    pos = int(i  * step)
    b.append(a[pos : pos + size])
    i+=1
  return b

hop_length = 512
sample_rate = 22050
frame_rate = sample_rate / hop_length
frequency_bins = int(1025 / 10)

window_size = int(frame_rate / 2) # /2 = 500ms
overlap = int(window_size / 2) # /2 = 250ms

sequence_length = 15 # 15 = 3.35 seconds, 30 = 7.5 seconds (with overlap)
sequence_overlap = int(sequence_length / 4)

# results in shape X: (n, 11, 21, 102), Y: (n, 11)

def prepareSet(n):
  X = []
  Y = []

  for species in tqdm(list(labels)): # progress bar
    filename = base + n + '/' + species + ".wav"
    
    y, _ = librosa.load(filename, sr=sample_rate)  # load file
    filtered = signal.lfilter(b, a, y)  # highpass filter
    del y
    D = librosa.stft(filtered, hop_length=hop_length)
    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)  #spectrogram
    new_size = (frequency_bins, len(S_db[0]))
    spectrogram = cv2.resize(S_db.transpose(), dsize=new_size, interpolation=cv2.INTER_NEAREST)

    label = to_categorical(labels[species], num_classes=len(labels)) # one hot encoding
    tiles = slideWindow(spectrogram, size=window_size, step=overlap)[:-1] # last one is not full
    denoised_tiles = np.apply_along_axis(denoise, axis=1, arr=tiles)
    del tiles

    sequences = slideWindow(denoised_tiles, size=sequence_length, step=sequence_overlap)[:-1] # last one is not full

    X.extend(sequences)
    Y.extend([label] * len(sequences))

  return X, Y

from sklearn.utils import shuffle
import h5py

"""
X_train, Y_train = prepareSet('train')
X_test, Y_test = prepareSet('test')
X_val, Y_val = prepareSet('val')

X_train, Y_train = shuffle(X_train, Y_train, random_state=42)
X_test, Y_test = shuffle(X_test, Y_test, random_state=42)
X_val, Y_val = shuffle(X_val, Y_val, random_state=42)

hf = h5py.File(base + 'data.h5', 'w')
hf.create_dataset('X_train', data=X_train)
hf.create_dataset('Y_train', data=Y_train)
hf.create_dataset('X_test', data=X_test)
hf.create_dataset('Y_test', data=Y_test)
hf.create_dataset('X_val', data=X_val)
hf.create_dataset('Y_val', data=Y_val)
hf.close()
"""

hf = h5py.File(base + 'data.h5', 'r')
X_train = hf.get('X_train')
Y_train = hf.get('Y_train')
X_test = hf.get('X_test')
Y_test = hf.get('Y_test')
X_val = hf.get('X_val')
Y_val = hf.get('Y_val')

print("Train:", np.shape(X_train), np.shape(Y_train))
print("Test:", np.shape(X_test), np.shape(Y_test))
print("Validation:", np.shape(X_val), np.shape(Y_val))

def stitch(a, r):
  return a[::r]
  
def plot_sequence(seq):
  plt.figure(figsize = (10, 5))
  stitched = stitch(seq, int(window_size / overlap))
  spec = np.rot90(np.concatenate(stitched))
  plt.imshow(spec, interpolation='nearest', aspect='auto', cmap='inferno')
  plt.colorbar()

plot_sequence(X_train[0])

"""# The Transformer model

From: https://keras.io/examples/timeseries/timeseries_transformer_classification/

Completely without convolution, just Attention like AST.
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

batch_size = 32
epochs = 50

"""
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    # Normalization and Attention
    x = layers.LayerNormalization(epsilon=1e-6)(inputs)
    x = layers.MultiHeadAttention(
        key_dim=head_size, num_heads=num_heads, dropout=dropout
    )(x, x)
    x = layers.Dropout(dropout)(x)
    res = x + inputs

    # Feed Forward Part
    x = layers.LayerNormalization(epsilon=1e-6)(res)
    x = layers.Dense(ff_dim, activation="relu")(x)
    x = layers.Dropout(dropout)(x)
    x = layers.Dense(inputs.shape[-1])(x)
    return x + res

def build_model(
    input_shape,
    n_classes,
    head_size,
    num_heads,
    ff_dim,
    num_transformer_blocks,
    mlp_units,
    dropout=0,
    mlp_dropout=0,
):
  inputs = keras.Input(shape=input_shape)
  x = inputs
  for _ in range(num_transformer_blocks):
      x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)

  x = layers.GlobalAveragePooling2D()(x)
  for dim in mlp_units:
      x = layers.Dense(dim, activation="relu")(x)
      x = layers.Dropout(mlp_dropout)(x)
  outputs = layers.Dense(n_classes, activation="softmax")(x)
  return keras.Model(inputs, outputs)

model = build_model(
    (sequence_length, window_size, frequency_bins),
    n_classes=len(labels),
    head_size=frequency_bins, # 128
    num_heads=2,  # Number of attention heads
    ff_dim=32,  # Hidden layer size in feed forward network inside transformer
    num_transformer_blocks=1,
    mlp_units=[64],
    mlp_dropout=0.4,
    dropout=0.25,
)
model.summary()

model.compile(
  loss="categorical_crossentropy",
  optimizer=keras.optimizers.Adam(learning_rate=1e-4),
  metrics=["categorical_accuracy"],
)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2, patience=5)

history = model.fit(np.asarray(X_train), np.asarray(Y_train),
                    batch_size=batch_size, epochs=epochs, validation_data=(np.asarray(X_val), np.asarray(Y_val)),
                    callbacks=[reduce_lr])
model.save('results/bat')

print(history.history.keys())

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
"""

model = keras.models.load_model('results/bat')

n = 12
plot_sequence(X_test[n])

pred = model.predict(np.expand_dims(X_test[n], axis=0))

species = list(labels)
print("Prediction:", species[np.argmax(pred)])
print("Ground truth:", species[np.argmax(Y_test[n])])

results = model.evaluate(np.asarray(X_test), np.asarray(Y_test), batch_size=batch_size)
print("test loss, test acc:", results)

import itertools

def plot_confusion_matrix(cm, class_names):
    """
    Returns a matplotlib figure containing the plotted confusion matrix.
    
    Args:
       cm (array, shape = [n, n]): a confusion matrix of integer classes
       class_names (array, shape = [n]): String names of the integer classes
    """
    
    # Normalize the confusion matrix.
    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)

    figure = plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("Confusion matrix")
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=90)
    plt.yticks(tick_marks, class_names)
    
    # Use white text if squares are dark; otherwise black.
    threshold = cm.max() / 2.
    
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        color = "white" if cm[i, j] > threshold else "black"
        plt.text(j, i, cm[i, j], horizontalalignment="center", color=color)
        
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

import sklearn

test_pred_raw = model.predict(np.asarray(X_test))
test_pred = np.argmax(test_pred_raw, axis=1)
test_y = np.argmax(np.asarray(Y_test), axis=1)

cm = sklearn.metrics.confusion_matrix(test_y, test_pred)
plot_confusion_matrix(cm, class_names=list(labels))

#!zip -r /content/drive/MyDrive/BAT/results/bat.zip /content/results/bat