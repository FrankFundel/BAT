{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce23cc9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../datasets/')\n",
    "from prepare_individuals import prepare, germanBats\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "classes = germanBats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f926e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:14<00:00,  1.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:03<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_len = 44                               # 88 bei 44100, 44 bei 22050 = 250ms ~ 25ms\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(\"../../datasets/prepared.h5\", classes, patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c6b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../call_nocall.indices', 'rb') as file:\n",
    "    indices, labels = pickle.load(file)\n",
    "        \n",
    "    train_indices = indices[0][:len(X_train)]\n",
    "    test_indices = indices[1][:len(X_test)]\n",
    "    val_indices = indices[2][:len(X_val)]\n",
    "    \n",
    "    X_train = X_train[train_indices]\n",
    "    X_test = X_test[test_indices]\n",
    "    X_val = X_val[val_indices]\n",
    "    \n",
    "    Y_train = Y_train[train_indices]\n",
    "    Y_test = Y_test[test_indices]\n",
    "    Y_val = Y_val[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0c6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3bcb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "'''species = [0, 1]\n",
    "def filterSpecies(s, X, Y):\n",
    "    idx = np.in1d(Y, s)\n",
    "    return X[idx], Y[idx]\n",
    "\n",
    "X_train, Y_train = filterSpecies(species, X_train, Y_train)\n",
    "X_test, Y_test = filterSpecies(species, X_test, Y_test)\n",
    "X_val, Y_val = filterSpecies(species, X_val, Y_val)\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "}'''\n",
    "\n",
    "species = np.asarray([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 2, 3, 3, 3, 3])\n",
    "\n",
    "Y_train = species[Y_train]\n",
    "Y_test = species[Y_test]\n",
    "Y_val = species[Y_val]\n",
    "\n",
    "classes = {\n",
    "    \"Pipistrellus pipistrellus\": 0,\n",
    "    \"Pipistrellus nathusii\": 1,\n",
    "    \"Pipistrellus kuhlii\": 2,\n",
    "    \"Other\": 3,\n",
    "}\n",
    "\n",
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ec1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from timm.data.mixup import Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5939c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stochdepth = True\n",
    "use_mixedprecision = False\n",
    "use_imbalancedsampler = False\n",
    "use_sampler = True\n",
    "use_cosinescheduler = False\n",
    "use_reduceonplateu = False\n",
    "use_nadam = False\n",
    "use_mixup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d49f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_args = {\n",
    "    'mixup_alpha': 1.,\n",
    "    'cutmix_alpha': 0.,\n",
    "    'cutmix_minmax': None,\n",
    "    'prob': 1.0,\n",
    "    'switch_prob': 0.,\n",
    "    'mode': 'batch',\n",
    "    'label_smoothing': 0,\n",
    "    'num_classes': len(list(classes))}\n",
    "mixup_fn = Mixup(**mixup_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "            \n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x = torchvision.ops.stochastic_depth(input=x, p=0.25, mode='batch', training=self.training)  # randomly zero input tensor\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335a469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77040aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        if use_mixup:\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=use_mixedprecision):\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if use_mixup:\n",
    "            running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "        else:\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Perform learning rate step\n",
    "        if use_cosinescheduler:\n",
    "            scheduler.step(epoch + batch / num_batches)\n",
    "    \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if use_mixup:\n",
    "                labels = torch.nn.functional.one_hot(labels.to(torch.int64), num_classes=len(list(classes))).float()\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update Weights\n",
    "            # optimizer.step()\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            if use_mixup:\n",
    "                running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "            else:\n",
    "                running_corrects += (predictions == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a34638",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.05\n",
    "warmup_epochs = 5\n",
    "wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80eec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "'''# Experiment: wrong sampling\n",
    "X = np.concatenate([X_train, X_test, X_val])\n",
    "Y = np.concatenate([Y_train, Y_test, Y_val])\n",
    "\n",
    "full_data = TensorDataset(torch.Tensor(np.expand_dims(X, axis=1)), torch.from_numpy(Y))\n",
    "train_size = int(0.75 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "val_size = int(0.2 * test_size)\n",
    "test_size -= val_size\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(full_data, [train_size, test_size, val_size],\n",
    "                                                                generator=torch.Generator().manual_seed(42))'''\n",
    "\n",
    "if use_mixup and len(X_train) % 2 != 0:\n",
    "    X_train = X_train[:-1]\n",
    "    Y_train = Y_train[:-1]\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(np.expand_dims(X_train, axis=1)), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(np.expand_dims(X_test, axis=1)), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(np.expand_dims(X_val, axis=1)), torch.from_numpy(Y_val))\n",
    "\n",
    "if use_imbalancedsampler:\n",
    "    train_loader = DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=ImbalancedDatasetSampler(test_data), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=ImbalancedDatasetSampler(val_data), batch_size=batch_size)\n",
    "elif use_sampler:\n",
    "    def getSampler(y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        weights = [len(y)/c for c in counts]\n",
    "        samples_weights = [weights[t] for t in y]\n",
    "        return WeightedRandomSampler(samples_weights, len(y))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, sampler=getSampler(Y_train), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=getSampler(Y_test), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=getSampler(Y_val), batch_size=batch_size)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(18, Block, image_channels=1, num_classes=len(list(classes)))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86fed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BAT/models/baseline_hierarchical/wandb/run-20220429_130338-2rqc22q6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/2rqc22q6\" target=\"_blank\">peachy-silence-29</a></strong> to <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f11acd701c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"BAT-baseline-hierarchical\", entity=\"frankfundel\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_mixup:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "if use_nadam:\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "scheduler = None\n",
    "if use_cosinescheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_epochs, T_mult=1)\n",
    "if use_reduceonplateu:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e066827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:48<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1022 Acc: 0.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 48.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8280 Acc: 0.6679\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:47<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7435 Acc: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 49.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6815 Acc: 0.7191\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:48<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5355 Acc: 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 48.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6667 Acc: 0.7624\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:47<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4483 Acc: 0.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 49.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9636 Acc: 0.6653\n",
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:46<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3516 Acc: 0.8684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 50.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6067 Acc: 0.7837\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:46<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2955 Acc: 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 51.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9292 Acc: 0.7508\n",
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2463 Acc: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 55.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8128 Acc: 0.7554\n",
      "==================== Starting at epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1861 Acc: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 54.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.1034 Acc: 0.7279\n",
      "==================== Starting at epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1575 Acc: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 55.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.2624 Acc: 0.7356\n",
      "==================== Starting at epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|████████████████████████████▎                                                                                                                          | 58/310 [00:08<00:36,  6.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================== Starting at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m Acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_loss, train_acc), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, epoch, criterion, optimizer, scheduler, dataloader, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update Weights\u001b[39;00m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "    \n",
    "    val_loss, val_acc = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "    \n",
    "    if use_reduceonplateu:\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'baseline_pipistrellus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c4b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▅▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▄▇▁█▆▆▅▅</td></tr><tr><td>val_loss</td><td>▃▂▂▅▁▄▃▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.94531</td></tr><tr><td>train_loss</td><td>0.15753</td></tr><tr><td>val_acc</td><td>0.73563</td></tr><tr><td>val_loss</td><td>1.26241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">peachy-silence-29</strong>: <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/2rqc22q6\" target=\"_blank\">https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/2rqc22q6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220429_130338-2rqc22q6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('baseline_pipistrellus.pth'))\n",
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 'baseline_pipistrellus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc0662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138/138 [00:09<00:00, 13.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "corrects = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm.tqdm(test_loader):\n",
    "    output = model(inputs.cuda()) # Feed Network\n",
    "\n",
    "    output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "    Y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    Y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef5247f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=-1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('baseline_pipistrellus_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7f01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7497734481196194\n",
      "F1-score: 0.7390666099918897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "corrects = np.equal(Y_pred, Y_true).sum()\n",
    "print(\"Test accuracy:\", corrects/len(Y_pred))\n",
    "print(\"F1-score:\", f1_score(Y_true, Y_pred, average=None).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e8207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
