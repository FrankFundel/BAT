{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce23cc9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../datasets/')\n",
    "from prepare_individuals import prepare, germanBats\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "classes = germanBats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f926e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:15<00:00,  1.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:03<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_len = 44                               # 88 bei 44100, 44 bei 22050 = 250ms ~ 25ms\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(\"../../datasets/prepared.h5\", classes, patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c6b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../call_nocall.indices', 'rb') as file:\n",
    "    indices, labels = pickle.load(file)\n",
    "        \n",
    "    train_indices = indices[0][:len(X_train)]\n",
    "    test_indices = indices[1][:len(X_test)]\n",
    "    val_indices = indices[2][:len(X_val)]\n",
    "    \n",
    "    X_train = X_train[train_indices]\n",
    "    X_test = X_test[test_indices]\n",
    "    X_val = X_val[val_indices]\n",
    "    \n",
    "    Y_train = Y_train[train_indices]\n",
    "    Y_test = Y_test[test_indices]\n",
    "    Y_val = Y_val[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0c6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3bcb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "'''species = [0, 1]\n",
    "def filterSpecies(s, X, Y):\n",
    "    idx = np.in1d(Y, s)\n",
    "    return X[idx], Y[idx]\n",
    "\n",
    "X_train, Y_train = filterSpecies(species, X_train, Y_train)\n",
    "X_test, Y_test = filterSpecies(species, X_test, Y_test)\n",
    "X_val, Y_val = filterSpecies(species, X_val, Y_val)\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "}'''\n",
    "\n",
    "species = np.asarray([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "Y_train = species[Y_train]\n",
    "Y_test = species[Y_test]\n",
    "Y_val = species[Y_val]\n",
    "\n",
    "classes = {\n",
    "    \"Nyctalus noctula\": 0,\n",
    "    \"Nyctalus leisleri\": 1,\n",
    "    \"Other\": 2,\n",
    "}\n",
    "\n",
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ec1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from timm.data.mixup import Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5939c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stochdepth = False\n",
    "use_mixedprecision = False\n",
    "use_imbalancedsampler = False\n",
    "use_sampler = True\n",
    "use_cosinescheduler = False\n",
    "use_reduceonplateu = False\n",
    "use_nadam = False\n",
    "use_mixup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d49f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_args = {\n",
    "    'mixup_alpha': 1.,\n",
    "    'cutmix_alpha': 0.,\n",
    "    'cutmix_minmax': None,\n",
    "    'prob': 1.0,\n",
    "    'switch_prob': 0.,\n",
    "    'mode': 'batch',\n",
    "    'label_smoothing': 0,\n",
    "    'num_classes': len(list(classes))}\n",
    "mixup_fn = Mixup(**mixup_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "            \n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x = torchvision.ops.stochastic_depth(input=x, p=0.25, mode='batch', training=self.training)  # randomly zero input tensor\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335a469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77040aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        if use_mixup:\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=use_mixedprecision):\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if use_mixup:\n",
    "            running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "        else:\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Perform learning rate step\n",
    "        if use_cosinescheduler:\n",
    "            scheduler.step(epoch + batch / num_batches)\n",
    "    \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if use_mixup:\n",
    "                labels = torch.nn.functional.one_hot(labels.to(torch.int64), num_classes=len(list(classes))).float()\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update Weights\n",
    "            # optimizer.step()\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            if use_mixup:\n",
    "                running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "            else:\n",
    "                running_corrects += (predictions == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a34638",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "warmup_epochs = 5\n",
    "wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80eec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "'''# Experiment: wrong sampling\n",
    "X = np.concatenate([X_train, X_test, X_val])\n",
    "Y = np.concatenate([Y_train, Y_test, Y_val])\n",
    "\n",
    "full_data = TensorDataset(torch.Tensor(np.expand_dims(X, axis=1)), torch.from_numpy(Y))\n",
    "train_size = int(0.75 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "val_size = int(0.2 * test_size)\n",
    "test_size -= val_size\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(full_data, [train_size, test_size, val_size],\n",
    "                                                                generator=torch.Generator().manual_seed(42))'''\n",
    "\n",
    "if use_mixup and len(X_train) % 2 != 0:\n",
    "    X_train = X_train[:-1]\n",
    "    Y_train = Y_train[:-1]\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(np.expand_dims(X_train, axis=1)), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(np.expand_dims(X_test, axis=1)), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(np.expand_dims(X_val, axis=1)), torch.from_numpy(Y_val))\n",
    "\n",
    "if use_imbalancedsampler:\n",
    "    train_loader = DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=ImbalancedDatasetSampler(test_data), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=ImbalancedDatasetSampler(val_data), batch_size=batch_size)\n",
    "elif use_sampler:\n",
    "    def getSampler(y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        weights = [len(y)/c for c in counts]\n",
    "        samples_weights = [weights[t] for t in y]\n",
    "        return WeightedRandomSampler(samples_weights, len(y))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, sampler=getSampler(Y_train), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=getSampler(Y_test), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=getSampler(Y_val), batch_size=batch_size)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(18, Block, image_channels=1, num_classes=len(list(classes)))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86fed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BAT/models/baseline_hierarchical/wandb/run-20220428_144434-13z1ef7a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/13z1ef7a\" target=\"_blank\">likely-jazz-20</a></strong> to <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fdc106b2fa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"BAT-baseline-hierarchical\", entity=\"frankfundel\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_mixup:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "if use_nadam:\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "scheduler = None\n",
    "if use_cosinescheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_epochs, T_mult=1)\n",
    "if use_reduceonplateu:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e066827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:46<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8783 Acc: 0.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7216 Acc: 0.7276\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5402 Acc: 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5300 Acc: 0.8089\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3616 Acc: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6023 Acc: 0.7981\n",
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2935 Acc: 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5860 Acc: 0.8454\n",
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2369 Acc: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6401 Acc: 0.7989\n",
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1876 Acc: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5542 Acc: 0.8056\n",
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1541 Acc: 0.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7232 Acc: 0.8129\n",
      "==================== Starting at epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:44<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1348 Acc: 0.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7989 Acc: 0.7802\n",
      "==================== Starting at epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1251 Acc: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8374 Acc: 0.7881\n",
      "==================== Starting at epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1207 Acc: 0.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8061 Acc: 0.8016\n",
      "==================== Starting at epoch 10 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1104 Acc: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7079 Acc: 0.8318\n",
      "==================== Starting at epoch 11 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0881 Acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 58.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7744 Acc: 0.7941\n",
      "==================== Starting at epoch 12 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0801 Acc: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9222 Acc: 0.7745\n",
      "==================== Starting at epoch 13 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0777 Acc: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0502 Acc: 0.7864\n",
      "==================== Starting at epoch 14 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0870 Acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 58.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9789 Acc: 0.7927\n",
      "==================== Starting at epoch 15 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0614 Acc: 0.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.2000 Acc: 0.7068\n",
      "==================== Starting at epoch 16 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0650 Acc: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 58.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.3125 Acc: 0.7118\n",
      "==================== Starting at epoch 17 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|███████████████████████████████████████████████████████████████▊                                                                                      | 132/310 [00:18<00:25,  7.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================== Starting at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m Acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_loss, train_acc), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, epoch, criterion, optimizer, scheduler, dataloader, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update Weights\u001b[39;00m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "    \n",
    "    val_loss, val_acc = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "    \n",
    "    if use_reduceonplateu:\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'baseline_nyctalus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c4b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▅▆▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▂▆▆█▆▆▆▅▅▆▇▅▄▅▅▁▁</td></tr><tr><td>val_loss</td><td>▃▁▂▂▂▁▃▃▄▃▃▃▅▆▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.97994</td></tr><tr><td>train_loss</td><td>0.06498</td></tr><tr><td>val_acc</td><td>0.71179</td></tr><tr><td>val_loss</td><td>1.31247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">likely-jazz-20</strong>: <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/13z1ef7a\" target=\"_blank\">https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/13z1ef7a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220428_144434-13z1ef7a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('baseline_nyctalus.pth'))\n",
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 'baseline_nyctalus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc0662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138/138 [00:09<00:00, 14.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "corrects = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm.tqdm(test_loader):\n",
    "    output = model(inputs.cuda()) # Feed Network\n",
    "\n",
    "    output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "    Y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    Y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef5247f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAGbCAYAAABQwfHbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5TUlEQVR4nO3deZxd8/nA8c+TSVJa+54NQSittdaitRNKbFWKVvGLWkoptZba2qJaiiKlrX1fGsReqihN7BJbxJYdEbFLZp7fH/cmnYwkc3PNvTNz7+ftdV5zzznf873PiZvMc7/bicxEkiRJ9adLewcgSZKk9mEiKEmSVKdMBCVJkuqUiaAkSVKdMhGUJEmqU10r/QZT3xnltGR1esuvOKC9Q5DaxNgPJ7V3CFKbmPb5mGjvGNoyx+m22HLtcj+2CEqSJNWpircISpIk1aSmxvaO4EuzRVCSJKlO2SIoSZJUjmxq7wi+NBNBSZKkcjR1/kTQrmFJkqQ6ZYugJElSGdKuYUmSpDpl17AkSZI6K1sEJUmSymHXsCRJUp1yQWlJkiR1VrYISpIklcOuYUmSpDrlrGFJkiR1VrYISpIklcEFpSVJkuqVXcOSJEnqrGwRlCRJKoddw5IkSXXKBaUlSZLUWdkiKEmSVA67hiVJkuqUs4YlSZLUWdkiKEmSVA67hiVJkuqUXcOSJEnqrGwRlCRJKkNm519H0ERQkiSpHDUwRtCuYUmSpDpli6AkSVI5amCyiImgJElSOWqga9hEUJIkqRxNnX+yiGMEJUmS6pSJoCRJUjmyqe22EkTENhHxUkSMjIhjZnF+6Yh4ICKeiohnI2Lb1uq0a1iSJKkcVZwsEhENwAXAlsBoYGhEDM7MEc2KnQBcn5kXRsQqwBBg2TnVa4ugJElSx7cuMDIzR2Xm58C1wIAWZRJYoPh6QWBsa5XaIihJklSONpw1HBEDgYHNDg3KzEHN9nsBbzXbHw2s16KaXwP3RMTPgK8BW7T2viaCkiRJ5WjDruFi0jeo1YJztgfw98w8OyI2AK6IiG9mzj5jtWtYkiSp4xsD9Gm237t4rLn9gOsBMvM/wDzAYnOq1ERQkiSpHE1Nbbe1bijQLyL6RkR3YHdgcIsybwKbA0TEyhQSwbfnVKldw5IkSWXIrN6C0pk5LSIOAe4GGoC/ZubwiDgFGJaZg4FfAH+JiMMpTBzZJzNzTvWaCEqSJHUCmTmEwpIwzY+d2Oz1CGDDuanTRFCSJKkcVVxHsFJMBCVJksrRhsvHtBcni0iSJNUpWwQlSZLKYdewJElSnbJrWJIkSZ2VLYKSJEnlsGtYkiSpTtk1LEmSpM7KFkFJkqRy2DUsSZJUp2ogEbRrWJIkqU7ZIihJklSOGpgsYiIoSZJUDruGJUmS1FnZIihJklSOGugatkWwg3v4sWF8b/f96b/bvlxyxfVfOD9u/ER+csjR7LrPwez0owN56NH/AjB16lROOP0P7LT3gez844P475PPVjt01bnvbr4hDzw+mIeG3cFBh+33hfPdu3fjgkvP4qFhd/CPe6+id5+eAHTr1pXfn38q9zx8M3c9dCPrb7j2jGuOOv5nPPbcvbzw5uNVuw9p6602YfjzD/HiiIf55VEHf+F89+7dufqqC3lxxMM8+vBtLLNMbwC22HxjHn/sTp568j4ef+xONt1kwxnX3H/vDQx//iGGDb2HYUPvYfHFF63a/agNNTW13dZOTAQ7sMbGRk47+wIuPPtUBl91MUPue5BXX3tjpjIXX3YNW2++MTf+/QJ+f/IxnHb2BQDcOPguAG654kL+cs5v+P35f6GpBsYyqHPo0qULp515PD/e7SA232AAO+zSn34rLTdTmR/stTPvT57Cd9bejksuvIJjf304AHv8aFcAttpoZ/bceSC/OvUoIgKA++7+FztssUd1b0Z1rUuXLvzp3NP53vZ7serqm/KDH+zIyiv3m6nMvj/Zg/fee5+vr7IR5/zpL/z2N8cD8M67k9hxp31Yc60t2He/n/P3v50703U/+tEhrL3OVqy9zla8/fa7VbsnqblWE8GIWDwifh8RQyLin9O3agRX75574WWW7t2TPr160K1bN/pv/l3++e/HZioTEXz00ccAfPDRxyy+WOFb5auvv8m631odgEUXXoj55/saw198pbo3oLq1xrdW5fXX3uTNN0Yzdeo0brv5Trbqv+lMZbbadlNuvHYwAEP+cS8bfmc9APqttDyPPlRo8Xv3nUlMeX8Kq635DQCeGvYsEye8U8U7Ub1bd501efXV13nttTeZOnUq11//D3bYfuuZyuyw/VZcccUNANx00x1stulGADz99HDGjZsAwPDhLzHvvPPQvXv36t6AKiub2m5rJ6W0CF4FvAD0BU4GXgeGVjAmFU18+x2WWmLxGftLLrEYE1t8azxo3724/e4H2HzHvTjoyBM57vADAVhphb48+PBjTJvWyOix4xnx0kjGT3i7qvGrfi3VYwnGjhk/Y3/c2Aks2WPJ2ZZpbGzkgykfsvAiC/HC8JfYsv+mNDQ00GfpXnxzjVXo2WupqsYvTdez11K8NXrsjP3RY8bRs+dSsy3T2NjI++9PYdFFF56pzM47b8dTTz3P559/PuPYJZf8gWFD7+H4435euRtQZdVJ1/CimXkpMDUz/5WZ+wKbzemCiBgYEcMiYtgll1/TJoFq1obc9yADtt2C+2+9kj///hSOPfUsmpqa2Gm7rVly8cX4wX6Hcsa5F7PGN1emS4MjAdTxXXflLYwbO4Hb/3ktJ/3maJ747zM0NjqsQZ3XKqusyG9PP44DDz56xrG9f/wz1lxrCzbZdCc22nBd9tpr13aMUPWslFnDU4s/x0XEdsBYYJE5XZCZg4BBAFPfGZVfKsI6tsTiizF+4v9a8SZMfIclWgwovvm2u7noD6cBsMY3V+bzz6fy3vtTWHThhTj6sANmlNvzgCNYtk+v6gSuujd+3MSZWvF69FySCcUuspZlxo+dQENDA/MvMB/vTZoMwCnHnzmj3M13XcFrr75ejbClLxg7Zjx9evecsd+7Vw/Gjh0/yzJjxoyjoaGBBRdcgHfffQ+AXr16cOMNl/KTfQ9j1Kj/jfGeXseHH37ENdfeyjprr8GVV95YhTtSm6qBsfelNBGdFhELAr8AjgQuAQ6vaFQC4JtfX5E3R49l9NjxTJ06lTvv/xebbrT+TGV6LLUEjw97GiiMC/zss89ZZKEF+eTTT/n4k08BePS/T9K1oYHl+y5T7VtQnXrmyefpu9wy9Fm6F926dWX7nftz710PzlTm3jsfZNfddwBg2wFb8ui/CzPe55l3Hub96rwAbLzJBjROa+SVl0ZVNX5puqHDnmaFFfqy7LJ96NatG7vtNoDbbr9npjK33X4Pe+/9fQB22WU7HnjwEQAWXHABBv/jco47/jc8+p9hM8o3NDTM6Dru2rUr2223BcOHv1SlO1Kbymy7rZ202iKYmbcXX74PbDqnsmpbXbs2cNzhB3LAESfQ2NjITt/bihWWW4bz/3I53/j6imy68focdcj+nHTGn7j8+lsIgtOOP4KIYNJ773PA4ccTXbqw5OKL8tsTj2zv21EdaWxs5Fe//A1X3HgRDQ0NXHfVLbz84qsccezBPPfUcO6960Guu/Jmzrnotzw07A4mv/c+h+z/SwAWW2wRrrjxIpoymTB2Ij//6bEz6j3u14czYNftmPer8/D48/dx7RU38cczLmyv21QdaGxs5LCfn8CQO66moUsX/n7ZdYwY8TK/PulIhj3xDLfffi9//du1XPb3P/HiiId5773J/HCvgwA4+KCfsMLyy3LC8YdzwvGF9pP+2+7BRx99zJA7rqZbt640NDRw//3/5pJLr2rP21Qdi5xNFhoR5wGzTVEz89BS3sCuYdWC5Vcc0N4hSG1i7IeT2jsEqU1M+3xMtHcMn1xzUpvlOPPucXK73M+cWgSHzeGcJElSfauBMYKzTQQz87JqBiJJkqTqanWMYEQ8wCy6iDNzjkvISJIk1bQaeNZwKcvHNJ9lMA+wCzCtMuFIkiR1ErXcNTxdZj7R4tAjEfHfCsUjSZKkKimla7j54tFdgG8BC1YsIkmSpM6gHdf/ayuldA0/QWGMYFDoEn4N2K+SQUmSJHV49dA1DKycmZ82PxARX6lQPJIkSaqSUh4x9+gsjv2nrQORJEnqVJqa2m5rJ7NtEYyIpYBewLwRsSaFrmGABYCvViE2SZKkjqvGl4/ZGtgH6A2czf8SwSnAcZUNS5IkSc1FxDbAuUADcElm/q7F+T8CmxZ3vwoskZkLzanO1p4scllE7JKZN32ZwCVJkmpNNlVv1nBENAAXAFsCo4GhETE4M0fMiCfz8Gblfwas2Vq9pYwR/FZELNSs4oUj4rS5iF2SJKn2VHeM4LrAyMwclZmfA9cCA+ZQfg/gmtYqLSUR7J+Zk6fvZOZ7wLYlXCdJkqQSRMTAiBjWbBvYokgv4K1m+6OLx2ZV1zJAX+Cfrb1vKcvHNETEVzLzs2Ll8wIuHyNJkupbG04WycxBwKA2qm534MbMbGytYCmJ4FXA/RHxt+L+T4DLvkRwkiRJnV8VxwgCY4A+zfZ7F4/Nyu7AwaVUWsqzhs+IiGeALYqHTs3Mu0upXJIkSW1iKNAvIvpSSAB3B37YslBEfB1YmBLXfC6lRRDgKaAbhUfNPVXiNZIkSbWrigtBZ+a0iDgEuJvC8jF/zczhEXEKMCwzBxeL7g5cm1nag5BbTQQjYjfgLOBBCmsJnhcRR2XmjWXchyRJUm2o8hNBMnMIMKTFsRNb7P96buospUXweGCdzJwIEBGLA/cBJoKSJKl+ldbo1qGVsnxMl+lJYNG7JV4nSZKkDqyUFsG7IuJu/rco4Q9o0SwpSZJUd6rcNVwJpcwaPioidgE2LB4alJm3VDYsSZKkDq66y8dUREmzhovPGvZ5w5IkSTWklFnDOwNnAEtQmDUcQGbmAhWOTZIkqeNqwyeLtJdSWgTPBLbPzBcqHYwkSVKnUQNdw6XM/p1gEihJklR7SmkRHBYR1wG3Ap9NP5iZN1cqKEmSpI4u62HWMLAA8DGwVbNjCZgISpKk+lUDXcOlLB/zk2oEIkmSpOoqafkYSZIktVAns4YlSZLUUg10DfvMYEmSpDrVaiIYEYdFxAJRcGlEPBkRW7V2nSRJUk1ramq7rZ2U0iK4b2ZOoTBreGFgb+B3FY1KkiSpo2vKttvaSSmJYBR/bgtckZnDmx2TJElSJ1XKZJEnIuIeoC9wbETMD3T+aTKSJElfRp3MGt4PWAMYlZkfR8SigGsLSpKk+lYDs4ZLSQQ3Kv5cLcIeYUmSpFpRSiJ4VLPX8wDrAk8Am1UkIkmSpE6gLp41nJnbN9+PiD7AOZUKSJIkqVOoga7hchaUHg2s3NaBSJIkqbpabRGMiPOA6SlvFwoTR56sYEySJEkdXw20CJYyRnBYs9fTgGsy85EKxSNJktQ51MPyMZl5WTUCkSRJUnXNNhGMiOf4X5fwTKeAzMzVKhaVJElSR1fjXcPfq1oUkiRJnUzWciKYmW9UMxBJkiRVV6vLx0TE+hExNCI+jIjPI6IxIqZUIzhJkqQOqynbbmsnpcwaPh/YHbgBWBv4EbBiJYOSJEnq8GrgySIlLSidmSOBhsxszMy/AdtUNixJkiRVWiktgh9HRHfg6Yg4ExhHeU8kkSRJqh01MFmklIRu72K5Q4CPgD7AzpUMSpIkqcOrgTGCpSSCO2bmp5k5JTNPzswjcGkZSZKkTq+URPDHszi2TxvHIUmS1KlkZpttpYiIbSLipYgYGRHHzKbMbhExIiKGR8TVrdU5pyeL7AH8EOgbEYObnVoAmFRSxJIkSbWqil26EdEAXABsCYwGhkbE4Mwc0axMP+BYYMPMfC8ilmit3jlNFnmUwsSQxYCzmx3/AHh27m9BkiRJZVoXGJmZowAi4lpgADCiWZn/Ay7IzPcAMnNia5W29mSRNyJiT2BsZn5afON5gd7A6+XdhyRJUg1owxbBiBgIDGx2aFBmDmq23wt4q9n+aGC9FtWsWKzrEaAB+HVm3jWn9y1l+ZjrgW8322+ksLj0OiVcyyar719KMalDe+mq/2vvEKQ20XePC9s7BKlmtOWzhotJ36BWC85ZV6AfsAmFRruHImLVzJw8uwtKmSzSNTM/n75TfN39y8UpSZKkuTCGwhJ+0/UuHmtuNDA4M6dm5mvAyxQSw9kqJRF8OyJ2mL4TEQOAd0oKWZIkqVZVdx3BoUC/iOhbfNDH7sDgFmVupdAaSEQsRqGreNScKi2la/hA4MqIOL+4P5rCItOSJEn1q4qPGs7MaRFxCHA3hfF/f83M4RFxCjAsMwcXz20VESMoDOU7KjPfnVO9pSSCr2Xm+hExXzGQD7/UnUiSJGmuZeYQYEiLYyc2e53AEcWtJKUkgq9ExE0UMs8XSq1YkiSplrXlZJH2UsoYwdUpDDa8NCIei4iBEbFAheOSJEnq2OrhWcOZ+UFm/iUzvw0cDZwEjIuIyyJihYpHKEmSpIpotWu4+EiT7YCfAMtSeMrIVcDGFPqpV6xgfJIkSR1TFSeLVEpJYwSBB4CzMvPRZsdvjIjvVCYsSZKkjq0WxgiWkgiuNruZwpl5aBvHI0mSpCqZbSIYESc2e93ydGbmqZUKSpIkqcOr8a7hj2Zx7KvA/sCigImgJEmqWzXdNZyZZ09/HRHzA4cB+wLXUpgwIkmSpE5sjmMEI2IRCqtT7wlcBqyVme9VIzBJkqQOrZa7hiPiLGBnYBCwqo+WkyRJ+p+s5UQQ+AXwGXACcHyzCSNBYbKITxeRJEn1q5YTwcws5fFzkiRJ6qRKWUdQkiRJLdR617AkSZJmpwYSQbt/JUmS6pQtgpIkSWWwa1iSJKlO1UIiaNewJElSnbJFUJIkqQy10CJoIihJklSOjNbLdHB2DUuSJNUpWwQlSZLKYNewJElSncomu4YlSZLUSdkiKEmSVAa7hiVJkupUOmtYkiRJnZUtgpIkSWWwa1iSJKlOOWtYkiRJnZYtgpIkSWXIbO8IvjwTQUmSpDLYNSxJkqROyxZBSZKkMtRCi6CJoCRJUhlqYYygXcOSJEmdQERsExEvRcTIiDhmFuf3iYi3I+Lp4rZ/a3XaIihJklSGanYNR0QDcAGwJTAaGBoRgzNzRIui12XmIaXWayIoSZJUhio/a3hdYGRmjgKIiGuBAUDLRHCu2DUsSZLUziJiYEQMa7YNbFGkF/BWs/3RxWMt7RIRz0bEjRHRp7X3tUVQkiSpDG35rOHMHAQM+pLV3AZck5mfRcQBwGXAZnO6wERQkiSpDE3V7RoeAzRv4etdPDZDZr7bbPcS4MzWKrVrWJIkqeMbCvSLiL4R0R3YHRjcvEBE9Gi2uwPwQmuV2iIoSZJUhmpOFsnMaRFxCHA30AD8NTOHR8QpwLDMHAwcGhE7ANOAScA+rdVrIihJklSGaj9ZJDOHAENaHDux2etjgWPnpk67hiVJkuqULYKSJEllqIVHzJkISpIklaHaXcOVYNewJElSnbJFUJIkqQxVXkewIkwEJUmSylDlZw1XhF3DkiRJdcoWQUmSpDI4a1iSJKlOOUZQFbfeJuvw81MOoUuXLtx2zRCuvOCamc6vvt5qHHbywSy/8nKcdNCpPHjHQzPOLdlzCY75/ZEs0XNxMpMj9z6W8aMnVPsWJAAeeeENzrz5YZqyiZ3WX4V9t/jWTOfPuuVhhr4yGoBPp05j0gef8PDv/o+hr4zmrFsenlHu9YmT+d2PtmKz1ZaravyqX5tuvhGn/u44Ghq6cNXlN3L+OZfMdL57926cd9EZrLbGKrw3aTIH7HsEb705lp2//z0OOnTfGeVW+cZKbPndXRj+3It069aN35x1At/eaF2ampr43WnncMfge6t9a5KJYEfWpUsXfnH6Yfx8j6OYOO5tLhlyIQ/f8yivv/LGjDITxkzg9MPPYI+f7vaF60849xgu/9NVDP33E8z71XloaqqBNmx1So1NTfz2xoe46MAdWHKh+djzDzfw3W/2ZfmlFplR5qidNprx+pqHnuXF0W8DsE6/3lz/y90BeP+jT9n+9CvZ4Ot9qnsDqltdunTht7//FbvtuB/jxk7grgeu5547H+Dll16dUeaHe+/K5Mnvs8Fa2zBg52054ddHcsC+R3DzDbdz8w23A/D1Vfrx96vOZ/hzLwLw8yMP4J23J7Hh2v2JCBZeeMF2uT99OU4WUUWtvObXGf36GMa+OY5pU6dx/z/+ycZbf3umMuNHT+DVF0aRTU0zHV+23zI0dG1g6L+fAOCTjz/ls08/q1rsUnPPvzGRPostSO/FFqRb1wa2XrMfDz732mzL3/nkK2zzrRW/cPzeZ15lw5WXZt7u3SoZrjTDmt9ajddGvcmbb4xm6tSp3HrTELbedrOZymy97WZcf80/ALj9H3ez0XfX/0I9O+2yHbfe9L9HxO6+586c98dBAGQmkyZNrtxNqGIy225rL7NNBCPinOLP2yJicMutahHWscWXWoyJYyfO2J847h0WX2rxkq7ts1xvPpzyIb/5y8n87e6LOfiEA+jSxbxf7WPi+x+y1MLzzdhfcqH5mPj+R7MsO3bSFMZOmsK6/Xp94dzdT71C/7W+mCBKldKjxxKMHTN+xv64sRPo0WPJFmWWZOyYcQA0NjbywZQPWGSRhWYqM2Dn/jMSwQUWnB+AXx5/KPf86yb+8vc/stjii1bwLqTZm1NmcEXx5++Bs2exqQNr6NrA6uuuyvmnXsT+2x5Iz6V7sO1uW7d3WFKr7n5yJFusvjwNLb64vP3+R4wc+67dwup01vzWanzy8ae8+MIrAHRtaKBX7x4Me/wptvruLgwb+jQnnfbLdo5S5WjKaLOtvcw2EczMJyKiARiYmf9quc2p0ogYGBHDImLY+I/GtnnQ9eLt8e+wRM8lZuwv0WMx3h7/dmnXjnubV4a/ytg3x9HY2MRDdz/Ciqv2q1So0hwtseB8jH/vwxn7EyZ/yBILfm2WZe966hW2WeuLn9V7nh7JpqstR7eGhorFKbU0btxEevZaasZ+j55LMm7chBZlJtCzVw8AGhoamH+B+Wfq6t1xl2255aY7ZuxPmjSZjz/6mDtuK0wOue3Wu1lttVUqeBeqlMxos629zLGvMDMbgWUiovvcVJqZgzJz7cxce6mv9fxSAdazF59+kd59e9Gjz1J07daVzQdsxsP3/Keka194+iXmW3A+FlqkMAD5Wxuuyesvv9HKVVJlfGPpJXjznfcZ8+4Upk5r5O6nXuG731z2C+Vem/AeUz7+jNWXXeoL5+568hX6zyJBlCrp6SefY7nll2HpZXrRrVs3dtxlW+6584GZytxz5wPstscAAL43YGseeeixGecigh123Gam8YEA99z1IN/eeF0ANv7u+rz80sgK34k0a6XMGh4FPFIcFzhjUE9m/qFiUQmAxsYm/njCefzh6jNo6NLA7dfdyWsvv87+R+7Di8+8zMP3PsrXV1+J3156CvMvOB8bbrkB+/9iH/babF+ampq44JSLOPe63xMRvPTcywy++o7W31SqgK4NXThml4058KLBNDUlA9ZbmRV6LMqfhzzOKksvwSbf7AsUkr1t1upHxMzfjse8O4Xxkz/kW8t/cdygVEmNjY0cd9RpXHPTJTQ0dOGaK2/mpRdH8svjfsbTTz3PPXc+wNVX3Mj5F5/Bf568i8nvvc8B+/5ixvUbbLg2Y8eM5803Rs9U72m/PpvzLj6DU397LO++M4mfH3x8tW9NbaAW1hGMbGWqSkScNKvjmXlyKW+wYa/NXLNEnd59l+zY3iFIbaLvHhe2dwhSmxg/+YV2z8Ie67lzm+U464+9uV3up9UWwekJX0R8NTM/rnxIkiRJHV8ttAi2up5IRGwQESOAF4v7q0fEnysemSRJkiqqlIXlzgG2Bt4FyMxngO9UMCZJkqQOrxZmDZf0iLnMfKvF4O3GyoQjSZLUOTS1XqTDKyURfCsivg1kRHQDDgNeqGxYkiRJqrRSEsGfAucCvYAxwD3AwZUMSpIkqaNLOv9kkVJmDb8D7FmFWCRJkjqNphpYIG+2iWBEnAfM9hYz89CKRCRJkqSqmFOL4LCqRSFJktTJNNVy13BmXtbyWER0AebLzCkVjUqSJKmDq4UxgqUsKH11RCwQEV8DngdGRMRRlQ9NkiRJlVTKgtKrFFsAdwTuBPoCe1cyKEmSpI6uqQ239lLK8jHdiusH7gicn5lTI6IG5slIkiSVry66hoGLgdeBrwEPRcQygGMEJUmSOrlS1hH8E/CnZofeiIhNKxeSJElSx1fTj5iLiL0y88qIOGI2Rf5QoZgkSZI6vJpOBCl0BQPMX41AJEmSVF1zWkfw4uLPk6sXjiRJUudQ7ckiEbENcC7QAFySmb+bTbldgBuBdTJzjg8IKWUdwRUj4v6IeL64v1pEnDDX0UuSJNWQpmi7rTUR0QBcAPQHVgH2iIhVZlFufuAw4PFS7qGUWcN/AY4FpgJk5rPA7qVULkmSpDaxLjAyM0dl5ufAtcCAWZQ7FTgD+LSUSktJBL+amf9tcWxaKZVLkiTVqiaizbaIGBgRw5ptA1u8XS/grWb7o4vHZoiItYA+mXlHqfdQyoLS70TE8kAW32RXYFypbyBJklSL2vLpGpk5CBhU7vUR0YXCii77zM11pSSCB1MI7OsRMQZ4DdhrbgOUJElS2cYAfZrt9y4em25+4JvAgxEBsBQwOCJ2mNOEkVIWlB4FbBERXwO6ZOYHZQQvSZJUU6q8juBQoF9E9KWQAO4O/HD6ycx8H1hs+n5EPAgc2dqs4TktKD3LhaSLWSaZ6YLSkiSpbjVF9ZaPycxpEXEIcDeF5WP+mpnDI+IUYFhmDi6n3jm1CLqQtCRJUgeRmUOAIS2OnTibspuUUuecFpR2IWlJkqTZaMvJIu2llMkikiRJaqEWnjVcyjqCkiRJqkG2CEqSJJWhlEfDdXSlPGv4sIhYIAoujYgnI2KragQnSZLUUbXlk0XaSyldw/tm5hRgK2BhYG/gdxWNSpIkSRVXStfw9DR1W+CK4po1NdAYKkmSVL56mTX8RETcA/QFjo2I+amNiTKSJEllq4UxgqUkgvsBawCjMvPjiFgU+ElFo5IkSVLFlZIIblT8uZo9wpIkSQW10D1aSiJ4VLPX8wDrAk8Am1UkIkmSpE6gLsYIZub2zfcjog9wTqUCkiRJUnWUs6D0aGDltg5EkiSpM6mLySIRcR7/a/3sQmHiyJMVjEmSJKnDq5cxgsOavZ4GXJOZj1QoHkmSJFVJKWMEL6tGIJIkSZ1JTbcIRsRzzHpCTACZmatVLCpJkqQOLmt8jOD3qhaFJEmSqm62iWBmvlHNQCRJkjqTWuga7tJagYhYPyKGRsSHEfF5RDRGxJRqBCdJktRRNbXh1l5aTQSB84E9gFeAeYH9gQsqGZQkSZIqr5REkMwcCTRkZmNm/g3YprJhSZIkdWzZhlt7KWUdwY8jojvwdEScCYyjxARSkiSpVtXCk0VKSej2LpY7BPgI6APsXMmgJEmSVHmlJII7ZuanmTklM0/OzCNwaRlJklTn6mWyyI9ncWyfNo5DkiSpU6mFRHBOTxbZA/gh0DciBjc7tQAwqdKBSZIkqbLmNFnkUQoTQxYDzm52/APg2UoGJUmS1NG152zfttLak0XeiIg9gbGZ+SlARMwL9AZer0qEkiRJHVC9zBq+npm7rxuBGyoTjiRJUudQC2MES0kEu2bm59N3iq+7Vy4kSZIkVUMpieDbEbHD9J2IGAC8U7mQJEmSOr56ebLIgcCVEXF+cX80hUWmSzLyw7HlxCV1KKvsdWl7hyC1iTceOqe9Q5BqRlMNTBcpJRF8LTPXj4j5ADLzwwrHJEmSpCoopWv4lYg4C+hjEihJklRQL5NFVgdeBi6NiMciYmBELFDhuCRJkjq0ao8RjIhtIuKliBgZEcfM4vxPI+K5iHg6Ih6OiFVaq7PVRDAzP8jMv2Tmt4GjgZOAcRFxWUSsUGLskiRJKlNENAAXAP2BVYA9ZpHoXZ2Zq2bmGsCZwB9aq7fVRDAiGiJih4i4BTiHwlNGlgNuA4bMzU1IkiTViip3Da8LjMzMUcWl/K4FBjQvkJlTmu1+jRIaG0uZLPIK8ABwVmY+2uz4jRHxnRKulyRJqjlt+WSRiBgIDGx2aFBmDmq23wt4q9n+aGC9WdRzMHAEhTWfN2vtfUtJBFeb3SSRzDy0hOslSZI0B8Wkb1CrBVuv5wLggoj4IXAC8OM5lZ9tIhgRJzZ7PYv3yVO/RJySJEmdWpXXERwD9Gm237t4bHauBS5srdI5jRH8aBZbAvtRmDQiSZJUt6o8a3go0C8i+kZEd2B3YHDzAhHRr9nudhSG983RbFsEM/PsZhXPDxwG7Eshwzx7dtdJkiSpbWXmtIg4BLgbaAD+mpnDI+IUYFhmDgYOiYgtgKnAe7TSLQytjBGMiEUoDDjcE7gMWCsz3/tytyJJktT5VXsh6MwcQosVWzLzxGavD5vbOuc0RvAsYGcKAxdX9akikiRJ/1MLzxqe0xjBXwA9Kcw4GRsRU4rbBxExZQ7XSZIkqROY0xjBUh4/J0mSVJc6f3tgaesISpIkqYVqjxGsBFv9JEmS6pQtgpIkSWWohckiJoKSJEll6PxpoF3DkiRJdcsWQUmSpDLUwmQRE0FJkqQyZA10Dts1LEmSVKdsEZQkSSqDXcOSJEl1qhaWj7FrWJIkqU7ZIihJklSGzt8eaCIoSZJUFruGJUmS1GnZIihJklQGZw1LkiTVKReUliRJUqdli6AkSVIZ7BqWJEmqU3YNS5IkqdOyRVCSJKkMdg1LkiTVqaa0a1iSJEmdlC2CkiRJZej87YEmgpIkSWXxWcOSJEnqtGwRlCRJKkMtrCNoIihJklSGWlg+xq5hSZKkOmWLoCRJUhlqYbKIiaAkSVIZamGMoF3DkiRJdcpEUJIkqQxNbbiVIiK2iYiXImJkRBwzi/NHRMSIiHg2Iu6PiGVaq9NEUJIkqQyZ2WZbayKiAbgA6A+sAuwREau0KPYUsHZmrgbcCJzZWr0mgpIkSR3fusDIzByVmZ8D1wIDmhfIzAcy8+Pi7mNA79YqdbKIJElSGao8a7gX8Faz/dHAenMovx9wZ2uVmghKkiSVoS0XlI6IgcDAZocGZeagMuvaC1gb+G5rZU0EJUmSytCWy8cUk745JX5jgD7N9nsXj80kIrYAjge+m5mftfa+jhGUJEnq+IYC/SKib0R0B3YHBjcvEBFrAhcDO2TmxFIqtUVQkiSpDNUcI5iZ0yLiEOBuoAH4a2YOj4hTgGGZORg4C5gPuCEiAN7MzB3mVK+JoCRJUhlKWfaljd9vCDCkxbETm73eYm7rtGtYkiSpTtkiKEmSVIa2nDXcXkwEJUmSytCWs4bbi13DkiRJdcoWwQ5o08034rQzjqehoQtXXX4j5/3xLzOd7969G+dffAarrfEN3ps0mYE/OYK33hzDLt//Hgcdut+Mcqt8cyW2+M7OjBr5On+57ByW7bs0jY2N3HvXA5z26z9U+7ZUZ76z2bc56bdH06VLF6678hYuOvevM53v3r0bZ//5dL65+spMfu99Dtnvl4x5ayzdunXl9D+cyKprrEI2NXHycWfy+CPDANh+52046PD9IZMJ49/m8J8ex3uTJrfD3alePfzUCM742800NTWx8+YbsN9OW850ftzbkzjhgiv54KNPaGxKfr7n9my81jd47pU3OOXia4FCK9KB3+/P5uut3h63oDZU5SeLVIQtgh1Mly5d+N3ZJ/LDXf+Pjdf9Hjvtsh0rrrT8TGV++KNdmTx5CuuvuTUX//kyfnXyLwC46Ybb2Xzjndh845045ICjefON0Qx/7kUALjzvb2y0zrZssfHOrLPeWmy2xcZVvzfVjy5dunDKmcexz24HsdW3d2KHnbdhhZWWm6nMbnvtxPuTp7DpOttz6YVXcsxJPwdg9x/tAkD/jXdl711+yvGn/IKIoKGhgRN/czQ/HLA//b/zfV4c/jI/2n/3at+a6lhjYxO/ufQGLjz+p9z6x+O485EnePWtcTOVGXTTPWy1wZpcf9bRnPnzH3P6JTcAsMLSPbjmjCO54fdHc+HxB3LKoOuY1tjYHrehNpSZbba1FxPBDmatb63Ga6Pe5I3XRzN16lRuvXkI22y3+Uxlttl2c66/+lYAbrv1bjb67gZfqGenXbfj1psKM8w/+eRTHvn34wBMnTqV554ZQc9eS1X2RlTXVl/rm7zx2lu89cYYpk6dxm233MWW/TeZqcyW/TflpmsLa6HeOfhevv2ddQHot9Jy/Off/wXg3XcmMWXKB6y25jeICCLgq1+dF4D55p+PiePfrt5Nqe49P/INll5qcXovuRjdunVlmw3X4oFhz81UJgI++uRTAD78+FMWX3gBAOb9Sne6NjQA8Nnn0yiu8Sa1u1YTwYjoEhHfrkYwgqV6LsnYMf/7hjl2zHiW6rHkTGV69FiCMcUyjY2NfDDlAxZZZKGZygzYuT+33HjHF+pfYMH52ar/pvz7X/9p++CloqV6LMG4MeNn7I8fO/ELn+MleyzBuLGFMoXP8YcsvMhCvPD8y2yxzXdpaGig99K9WHX1lenRa0mmTZvGr448nTsfvpHHh99Hv5WW47orb6nqfam+TZg0mSUXXWjG/pKLLMTEd9+fqcyBu/Xn9oeGscUBv+Kg317EsfvuOuPcs6+8zk6H/4ZdfvFbfvV/u81IDNV5NZFttrWXVhPBzGwCLpibSiNiYEQMi4hhn3w+udzYVKa1vrUan3z8KS++8MpMxxsaGrjo0rO55KIreOP10e0UnTRn1191K+PGTmDw/Vdz4m+O4on/PkNjYxNdu3Zlz31343ub/ID1vrEFL454hYMO36/1CqUquvPhJxiw6Xrcd/Gp/PnYn3LceVfQ1FRYZGS1fstyyx+P45rfHcmlt9zLZ59Pbedo9WVlG/7XXkrtGr4/InaJEtuyM3NQZq6dmWvP232h8qOrQ+PHTqBnrx4z9nv2Worx4ybMVGbcuIn0KpZpaGhg/gXmZ1KzAfM77rItt9z0xdbAs889hddefYNBF15emeClovHjJtKj2fCDpXou8YXP8YRxE+nRs1Cm8Dmej/cmTaaxsZHTTvg9223yAwbu9XMWWHB+Xnv1DVZZdSUA3ix+ibnj1rtZax0H26t6llxkISa8O3nG/oRJk1li0QVnKnPLPx9j6w3WBGD1lfry2dRpvPfBRzOVWa73Usw7z1cY2WJ8odQeSk0EDwBuAD6PiCkR8UFETKlgXHXrqSefY7nll2HpZXrRrVs3dtx5W+4e8s+Zytw95J/s9sMdAdh+x615+KHHZpyLCHbYqT+3tkgEjznhMOZfcH5OOOY3Fb8H6dmnhrPsckvTe+ledOvWle132ob77vzXTGXuu+tBdtm98AjM/jtsOWNc4DzzzsO8xXGAG22yPo3TGhn50ijGj5tIvxWXY5FFFy6e24BXX36tineleveNFZbmjXFvM3rCu0ydOo27HnmSTdZedaYySy22MI8/9zIAo0aP5/OpU1lkgfkYPeHdGZNDxr49idfHTqDn4otU/R7Utpoy22xrLyUtH5OZ81c6EBU0NjZy7JGncu3Nl9LQ0IVrrryJl14cyS+P+xnPPPU8d9/5AFdfcSPnDzqTx566m8nvvc8B+x4x4/oNNlyHsWPGzdT126Pnkhx+1IG8/NKr3PfQzQD89S9XcdXlN1b9/lQfGhsbOeno33L5DRfSpaELN1x9K6+89CqHH3MQzz09nPvu+hfXXXkLf7zwdB4YehvvT57Cz/b/JQCLLrYIl994IU1NTYwfN5EjDjwegInj3+bcsy7mutv/yrSp0xjz1jiOPORX7XmbqjNdGxo4br9dOfD0P9PY1MSOm67PCn16cMG1d7DK8kuz6TqrcuSPduTki6/lijseIAhOPXhPIoKnXnyVv956H10bGoguwfH778bCC8zX3rekL6nzLx4DUcqU5WKX8J5A38w8NSL6AD0y87+tXbvkgl+vhT8n1bmvdv1Ke4cgtYkXHzizvUOQ2sRXVtu63adeb9xr8zbLcf495v52uZ9Su4b/DGwA/LC4/yFzOYFEkiSpltTCrOFSnyyyXmauFRFPAWTmexHRvYJxSZIkdWj19GSRqRHRQLE7PCIWB5oqFpUkSZIqrtQWwT8BtwBLRMTpwK7ACRWLSpIkqYNrz0fDtZVSZw1fFRFPAJsDAeyYmS9UNDJJkqQOrBa6hkttEQR4BZgy/ZqIWDoz36xIVJIkSaq4khLBiPgZcBIwAWik0CqYwGqVC02SJKnjas9Hw7WVUlsEDwNWysx3KxmMJElSZ1ELYwRLnTX8FvB+JQORJElSdc2xRTAipj+7bBTwYETcAXw2/Xxm/qGCsUmSJHVY9TBZZPozht8sbt2LG9TGI/YkSZLKUgtdw3NMBDPzZICI+H5m3tD8XER8v5KBSZIkqbJKHSN4bInHJEmS6kLNP2s4IvoD2wK9IuJPzU4tAEyrZGCSJEkdWT0sHzMWGAZ8H3i5eGwahfUED69gXJIkSaqw1hLBEcCeFCaI7Fs8tjTwN+D2CsYlSZLUoTXVwGSR1sYIngksDCyTmWtl5lrAcsCCwO8rHZwkSVJHlW34X3tpLRH8HjAwMz+YfiAzpwAHUhg7KEmSpE6qta7hzFkskpOZjRHR+dtDJUmSylQPXcMjIuJHLQ9GxF7Ai5UJSZIkqeOrha7h1loEDwZujoh9gSeKx9YG5gV2qmRgkiRJqqzWniwyBlgvIjYDvlE8PCQz7694ZJIkSR1YLXQNt9YiCEBm/hP4Z4VjkSRJ6jRqYUHpUh8xJ0mSpHYUEdtExEsRMTIijpnF+e9ExJMRMS0idi2lzpJaBCVJkjSzanYNR0QDcAGwJTAaGBoRgzNzRLNibwL7AEeWWq+JoCRJUhmq3DW8LjAyM0cBRMS1wAAKT4ErxJP5evFcU6mV2jUsSZLUziJiYEQMa7YNbFGkF/BWs/3RxWNfii2CkiRJZcgsueGthLpyEDCozSoskYmgJElSGZqq2zU8BujTbL938diXYtewJElSxzcU6BcRfSOiO7A7MPjLVmoiKEmSVIbMbLOthPeaBhwC3A28AFyfmcMj4pSI2AEgItaJiNHA94GLI2J4a/XaNSxJklSGKncNk5lDgCEtjp3Y7PVQCl3GJbNFUJIkqU7ZIihJklSGUrp0OzoTQUmSpDJU88kilWLXsCRJUp2yRVCSJKkMVX7EXEWYCEqSJJXBMYKSJEl1qtrLx1SCYwQlSZLqlC2CkiRJZbBrWJIkqU65fIwkSZI6LVsEJUmSymDXsCRJUp1y1rAkSZI6LVsEJUmSymDXsCRJUp1y1rAkSZI6LVsEJUmSypA1MFnERFCSJKkMdg1LkiSp07JFUJIkqQzOGpYkSapTtTBG0K5hSZKkOmWLoCRJUhnsGpYkSapTtZAI2jUsSZJUp2wRlCRJKkPnbw+EqIVmzXoXEQMzc1B7xyF9WX6WVSv8LKuzsGu4Ngxs7wCkNuJnWbXCz7I6BRNBSZKkOmUiKEmSVKdMBGuD41BUK/wsq1b4WVan4GQRSZKkOmWLoCRJUp0yEZQkSapTJoIliIiMiLOb7R8ZEb8uo55lI+KHJZZ7fm7rr5SI2CciepZY7vxqxKTyddbPc0T8OiKObKXMTyPiR3M4P9ef0YhYOyL+NDfXqLZERO+I+EdEvBIRr0bEuRHRPSLWiIhtm5Vr9TMqdTQmgqX5DNg5Ihb7kvUsC7T6i7MD2gdoNRFUp1Gzn+fMvCgzL2+r+iKia2YOy8xD26pOdS4REcDNwK2Z2Q9YEZgPOB1YA9h29lfP9Xs1tFVdUqlMBEszjcIMsMObH4yI+SPitYjoVtxfYPp+RKwQEfdFxDMR8WRELA/8Dtg4Ip6OiMOLLSX/Lp5/MiK+3fKNW7ZgRMTtEbFJRDRExN8j4vmIeC4iDp/FtX+PiD9FxKMRMSoidi0ej4g4q9m1P2h2zdHFY89ExO+K16wNXFWMe96IeH16ElFsLXlwFu+9fUQ8HhFPFf8clizrT16V0Ck/zy3qWT4i7oqIJ4rv+fXi8RktMhFxaESMiIhnI+LaWdSxeETcFBFDi9uGzeq4IiIeAa4oxnf7XP4Zq3ZsBnyamX8DyMxGCn939gfOBH5Q/Dsw/d/RVSLiweK/uTO+QETEXhHx32LZi6cnfRHxYUScHRHPABtU9c4kfNbw3LgAeDYizpx+IDM/KCZB2wG3ArsDN2fm1Ii4CvhdZt4SEfNQSLqPAY7MzO8BRMRXgS0z89OI6AdcQyHpKsUaQK/M/GaxroVmU64HsBHwdWAwcCOwc/H61YHFgKER8VDx2ABgvcz8OCIWycxJEXFIMe5hxfcqJb6HgfUzMyNif+CXwC9KvDdVXmf9PE83CPhpZr4SEesBf6bwC7u5Y4C+mfnZbOo7F/hjZj4cEUsDdwMrF8+tAmyUmZ9ExCYl3oNq0zeAJ5ofyMwpEfE68Ddgxcw8BApfIij8W7spMD/wUkRcCKwA/ADYsPj36c/AnsDlwNeAxzPTfx/VLkwES1T8i385cCjwSbNTl1BIcm4FfgL8X0TMT+GX2i3Faz+FWSZQ3YDzI2INoJFCl0OpRgHLRcR5wB3APbMpd2tmNgEjmrXKbQRcU/xmOyEi/gWsA3wX+FtmflyMe9JcxNNSb+C6iOgBdAde+xJ1qY114s8zETEf8G3ghmYxfGUWRZ+l0JJ9a/F+WtqCQuvN9P0FinUDDM7MT2ZxjdSaOzLzM+CziJgILAlsDnyLwpdugHmBicXyjcBN7RGoBHYNz61zgP0ofIMDIDMfAZYttho0ZObcDIo/HJhAoWVubQoJU0vTmPn/0zzF932veN2DwE8p/AKflc+avS6pKa8EzWOaZzZlzgPOz8xVgQPmUE7t5xw63+eZ4vWTM3ONZtvKsyi3HYWWz7Uo/AJu+cW3C4VW6+l19MrMD4vnPprD+6u+jKCQxM0QEQsAS1P4PLfU/N/cRgoNLgFc1uyztlJm/rpY5tPil3KpXZgIzoViC9n1FH55Nnc5cDWFbgIy8wNgdETsCBARXyl2m31AobtgugWBccUWu72BWQ0Ufh1YIyK6REQfYN1inYsBXTLzJuAECr/sSvVvCuNaGiJiceA7wH+Be4GfFGMlIhYplm8Z9+v87x/GXWbzHgsCY4qvfzwXsalKOuvnOTOnAK9FxPeL10ZErN68TER0Afpk5gPA0cXY5mtR1T3Az5pds8bs3lN17X7gq1GcjV4c23c28HcKX3zmn/2lM9Wxa0QsUaxjkYhYpjLhSnPHRHDunU1hXF1zVwELUxgTNd3ewKER8SzwKLAUha6qxigMuD+cwrimHxcHCX+dWbdCPEKhW3UE8CfgyeLxXsCDEfE0cCVw7Fzcwy3FWJ4B/gn8MjPHZ+ZdFMYRDivWO30ZhL8DFxUHOc8LnAycGxHDKHzjnZVfU+i6ewJ4Zy5iU3V11s/znsB+xfcaTmFsa3MNwJUR8RzwFPCnzJzcosyhwNrFySQjKLRESjPJwuO3dgK+HxGvAC8DnwLHAQ9QGF7QfLLIrOoYQeELzj3Fv0P3Uhi/LbU7HzHXBqIws3ZAZu7d3rFIX5afZ0mqH04W+ZKKg9v704ZrSUntxc+zJNUXWwQlSZLqlGMEJUmS6pSJoCRJUp0yEZQkSapTJoKSJEl1ykRQkiSpTv0/W6ArjR4VekAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=-1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('baseline_nyctalus_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7f01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8263479836882646\n",
      "F1-score: 0.8261809324047774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "corrects = np.equal(Y_pred, Y_true).sum()\n",
    "print(\"Test accuracy:\", corrects/len(Y_pred))\n",
    "print(\"F1-score:\", f1_score(Y_true, Y_pred, average=None).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e8207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
