{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce23cc9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../datasets/')\n",
    "from prepare_individuals import prepare, germanBats\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "classes = germanBats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f926e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:15<00:00,  1.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:04<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_len = 44                               # 88 bei 44100, 44 bei 22050 = 250ms ~ 25ms\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(\"../../datasets/prepared.h5\", classes, patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c6b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../call_nocall.indices', 'rb') as file:\n",
    "    indices, labels = pickle.load(file)\n",
    "        \n",
    "    train_indices = indices[0][:len(X_train)]\n",
    "    test_indices = indices[1][:len(X_test)]\n",
    "    val_indices = indices[2][:len(X_val)]\n",
    "    \n",
    "    X_train = X_train[train_indices]\n",
    "    X_test = X_test[test_indices]\n",
    "    X_val = X_val[val_indices]\n",
    "    \n",
    "    Y_train = Y_train[train_indices]\n",
    "    Y_test = Y_test[test_indices]\n",
    "    Y_val = Y_val[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0c6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3bcb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "'''species = [0, 1]\n",
    "def filterSpecies(s, X, Y):\n",
    "    idx = np.in1d(Y, s)\n",
    "    return X[idx], Y[idx]\n",
    "\n",
    "X_train, Y_train = filterSpecies(species, X_train, Y_train)\n",
    "X_test, Y_test = filterSpecies(species, X_test, Y_test)\n",
    "X_val, Y_val = filterSpecies(species, X_val, Y_val)\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "}'''\n",
    "\n",
    "species = np.asarray([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2])\n",
    "\n",
    "Y_train = species[Y_train]\n",
    "Y_test = species[Y_test]\n",
    "Y_val = species[Y_val]\n",
    "\n",
    "classes = {\n",
    "    \"Eptesicus serotinus\": 0,\n",
    "    \"Eptesicus nilssonii\": 1,\n",
    "    \"Other\": 2,\n",
    "}\n",
    "\n",
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ec1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from timm.data.mixup import Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5939c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stochdepth = True\n",
    "use_mixedprecision = False\n",
    "use_imbalancedsampler = False\n",
    "use_sampler = True\n",
    "use_cosinescheduler = False\n",
    "use_reduceonplateu = False\n",
    "use_nadam = False\n",
    "use_mixup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d49f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_args = {\n",
    "    'mixup_alpha': 1.,\n",
    "    'cutmix_alpha': 0.,\n",
    "    'cutmix_minmax': None,\n",
    "    'prob': 1.0,\n",
    "    'switch_prob': 0.,\n",
    "    'mode': 'batch',\n",
    "    'label_smoothing': 0,\n",
    "    'num_classes': len(list(classes))}\n",
    "mixup_fn = Mixup(**mixup_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "            \n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x = torchvision.ops.stochastic_depth(input=x, p=0.25, mode='batch', training=self.training)  # randomly zero input tensor\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335a469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77040aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        if use_mixup:\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=use_mixedprecision):\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if use_mixup:\n",
    "            running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "        else:\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Perform learning rate step\n",
    "        if use_cosinescheduler:\n",
    "            scheduler.step(epoch + batch / num_batches)\n",
    "    \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if use_mixup:\n",
    "                labels = torch.nn.functional.one_hot(labels.to(torch.int64), num_classes=len(list(classes))).float()\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update Weights\n",
    "            # optimizer.step()\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            if use_mixup:\n",
    "                running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "            else:\n",
    "                running_corrects += (predictions == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a34638",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "warmup_epochs = 5\n",
    "wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80eec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "'''# Experiment: wrong sampling\n",
    "X = np.concatenate([X_train, X_test, X_val])\n",
    "Y = np.concatenate([Y_train, Y_test, Y_val])\n",
    "\n",
    "full_data = TensorDataset(torch.Tensor(np.expand_dims(X, axis=1)), torch.from_numpy(Y))\n",
    "train_size = int(0.75 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "val_size = int(0.2 * test_size)\n",
    "test_size -= val_size\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(full_data, [train_size, test_size, val_size],\n",
    "                                                                generator=torch.Generator().manual_seed(42))'''\n",
    "\n",
    "if use_mixup and len(X_train) % 2 != 0:\n",
    "    X_train = X_train[:-1]\n",
    "    Y_train = Y_train[:-1]\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(np.expand_dims(X_train, axis=1)), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(np.expand_dims(X_test, axis=1)), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(np.expand_dims(X_val, axis=1)), torch.from_numpy(Y_val))\n",
    "\n",
    "if use_imbalancedsampler:\n",
    "    train_loader = DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=ImbalancedDatasetSampler(test_data), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=ImbalancedDatasetSampler(val_data), batch_size=batch_size)\n",
    "elif use_sampler:\n",
    "    def getSampler(y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        weights = [len(y)/c for c in counts]\n",
    "        samples_weights = [weights[t] for t in y]\n",
    "        return WeightedRandomSampler(samples_weights, len(y))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, sampler=getSampler(Y_train), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=getSampler(Y_test), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=getSampler(Y_val), batch_size=batch_size)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(18, Block, image_channels=1, num_classes=len(list(classes)))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86fed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BAT/models/baseline_hierarchical/wandb/run-20220429_131135-3c6r96n0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/3c6r96n0\" target=\"_blank\">bright-flower-30</a></strong> to <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f9ced373760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"BAT-baseline-hierarchical\", entity=\"frankfundel\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_mixup:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "if use_nadam:\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "scheduler = None\n",
    "if use_cosinescheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_epochs, T_mult=1)\n",
    "if use_reduceonplateu:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e066827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:45<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7076 Acc: 0.6988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6959 Acc: 0.6662\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3886 Acc: 0.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7511 Acc: 0.7810\n",
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2727 Acc: 0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8565 Acc: 0.7741\n",
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1754 Acc: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8052 Acc: 0.7958\n",
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1574 Acc: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6386 Acc: 0.8214\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1173 Acc: 0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7812 Acc: 0.7785\n",
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0863 Acc: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.1080 Acc: 0.7585\n",
      "==================== Starting at epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0759 Acc: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.8652 Acc: 0.8000\n",
      "==================== Starting at epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:43<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0778 Acc: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 57.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.2785 Acc: 0.7699\n",
      "==================== Starting at epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|████▊                                                                                                                                                  | 10/310 [00:01<00:46,  6.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================== Starting at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m Acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_loss, train_acc), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, epoch, criterion, optimizer, scheduler, dataloader, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39muse_mixedprecision):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Forward Pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     _, predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Compute Loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m---> 42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentity_downsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentity_downsample(identity)\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstochastic_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# randomly zero input tensor\u001b[39;00m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/ops/stochastic_depth.py:44\u001b[0m, in \u001b[0;36mstochastic_depth\u001b[0;34m(input, p, mode, training)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m survival_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     noise\u001b[38;5;241m.\u001b[39mdiv_(survival_rate)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/opt/Python/3.8.6/lib/python3.8/traceback.py:348\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    346\u001b[0m fnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m--> 348\u001b[0m     co \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\n\u001b[1;32m    349\u001b[0m     filename \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_filename\n\u001b[1;32m    350\u001b[0m     name \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_name\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "    \n",
    "    val_loss, val_acc = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "    \n",
    "    if use_reduceonplateu:\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'baseline_eptesicus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c4b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▅▆▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆▆▇█▆▅▇▆</td></tr><tr><td>val_loss</td><td>▂▂▃▃▁▃▆▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.97732</td></tr><tr><td>train_loss</td><td>0.07778</td></tr><tr><td>val_acc</td><td>0.76985</td></tr><tr><td>val_loss</td><td>1.27846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bright-flower-30</strong>: <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/3c6r96n0\" target=\"_blank\">https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/3c6r96n0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220429_131135-3c6r96n0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('baseline_eptesicus.pth'))\n",
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 'baseline_eptesicus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc0662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138/138 [00:09<00:00, 14.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "corrects = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm.tqdm(test_loader):\n",
    "    output = model(inputs.cuda()) # Feed Network\n",
    "\n",
    "    output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "    Y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    Y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef5247f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=-1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('baseline_eptesicus_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7f01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7599682827367468\n",
      "F1-score: 0.7563472030948711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "corrects = np.equal(Y_pred, Y_true).sum()\n",
    "print(\"Test accuracy:\", corrects/len(Y_pred))\n",
    "print(\"F1-score:\", f1_score(Y_true, Y_pred, average=None).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77c2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
