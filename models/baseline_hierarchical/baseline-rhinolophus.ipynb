{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce23cc9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../datasets/')\n",
    "from prepare_individuals import prepare, germanBats\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "classes = germanBats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f926e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:15<00:00,  1.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:06<00:00,  2.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:03<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_len = 44                               # 88 bei 44100, 44 bei 22050 = 250ms ~ 25ms\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(\"../../datasets/prepared.h5\", classes, patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c6b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../call_nocall.indices', 'rb') as file:\n",
    "    indices, labels = pickle.load(file)\n",
    "        \n",
    "    train_indices = indices[0][:len(X_train)]\n",
    "    test_indices = indices[1][:len(X_test)]\n",
    "    val_indices = indices[2][:len(X_val)]\n",
    "    \n",
    "    X_train = X_train[train_indices]\n",
    "    X_test = X_test[test_indices]\n",
    "    X_val = X_val[val_indices]\n",
    "    \n",
    "    Y_train = Y_train[train_indices]\n",
    "    Y_test = Y_test[test_indices]\n",
    "    Y_val = Y_val[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0c6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3bcb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33868\n",
      "(19839, 44, 257) (19839,)\n"
     ]
    }
   ],
   "source": [
    "'''species = [0, 1]\n",
    "def filterSpecies(s, X, Y):\n",
    "    idx = np.in1d(Y, s)\n",
    "    return X[idx], Y[idx]\n",
    "\n",
    "X_train, Y_train = filterSpecies(species, X_train, Y_train)\n",
    "X_test, Y_test = filterSpecies(species, X_test, Y_test)\n",
    "X_val, Y_val = filterSpecies(species, X_val, Y_val)\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "}'''\n",
    "\n",
    "species = np.asarray([0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "Y_train = species[Y_train]\n",
    "Y_test = species[Y_test]\n",
    "Y_val = species[Y_val]\n",
    "\n",
    "classes = {\n",
    "    \"Rhinolophus ferrumequinum\": 0,\n",
    "    \"Rhinolophus hipposideros\": 1,\n",
    "    \"Other\": 2,\n",
    "}\n",
    "\n",
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ec1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from timm.data.mixup import Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5939c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stochdepth = False\n",
    "use_mixedprecision = False\n",
    "use_imbalancedsampler = False\n",
    "use_sampler = True\n",
    "use_cosinescheduler = False\n",
    "use_reduceonplateu = False\n",
    "use_nadam = False\n",
    "use_mixup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d49f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_args = {\n",
    "    'mixup_alpha': 1.,\n",
    "    'cutmix_alpha': 0.,\n",
    "    'cutmix_minmax': None,\n",
    "    'prob': 1.0,\n",
    "    'switch_prob': 0.,\n",
    "    'mode': 'batch',\n",
    "    'label_smoothing': 0,\n",
    "    'num_classes': len(list(classes))}\n",
    "mixup_fn = Mixup(**mixup_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "            \n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x = torchvision.ops.stochastic_depth(input=x, p=0.25, mode='batch', training=self.training)  # randomly zero input tensor\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335a469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77040aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        if use_mixup:\n",
    "            inputs, labels = mixup_fn(inputs, labels)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=use_mixedprecision):\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if use_mixup:\n",
    "            running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "        else:\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Perform learning rate step\n",
    "        if use_cosinescheduler:\n",
    "            scheduler.step(epoch + batch / num_batches)\n",
    "    \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if use_mixup:\n",
    "                labels = torch.nn.functional.one_hot(labels.to(torch.int64), num_classes=len(list(classes))).float()\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update Weights\n",
    "            # optimizer.step()\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            if use_mixup:\n",
    "                running_corrects += (predictions == torch.max(labels, 1)[1]).sum().item()\n",
    "            else:\n",
    "                running_corrects += (predictions == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80eec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "lr = 0.01\n",
    "warmup_epochs = 5\n",
    "wd = 0.01\n",
    "\n",
    "'''# Experiment: wrong sampling\n",
    "X = np.concatenate([X_train, X_test, X_val])\n",
    "Y = np.concatenate([Y_train, Y_test, Y_val])\n",
    "\n",
    "full_data = TensorDataset(torch.Tensor(np.expand_dims(X, axis=1)), torch.from_numpy(Y))\n",
    "train_size = int(0.75 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "val_size = int(0.2 * test_size)\n",
    "test_size -= val_size\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(full_data, [train_size, test_size, val_size],\n",
    "                                                                generator=torch.Generator().manual_seed(42))'''\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(np.expand_dims(X_train, axis=1)), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(np.expand_dims(X_test, axis=1)), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(np.expand_dims(X_val, axis=1)), torch.from_numpy(Y_val))\n",
    "\n",
    "if use_imbalancedsampler:\n",
    "    train_loader = DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=ImbalancedDatasetSampler(test_data), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=ImbalancedDatasetSampler(val_data), batch_size=batch_size)\n",
    "elif use_sampler:\n",
    "    def getSampler(y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        weights = [len(y)/c for c in counts]\n",
    "        samples_weights = [weights[t] for t in y]\n",
    "        return WeightedRandomSampler(samples_weights, len(y))\n",
    "    \n",
    "    train_loader = DataLoader(train_data, sampler=getSampler(Y_train), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=getSampler(Y_test), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=getSampler(Y_val), batch_size=batch_size)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "881cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(18, Block, image_channels=1, num_classes=len(list(classes)))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a86fed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BAT/models/baseline_hierarchical/wandb/run-20220427_161800-low0cwff</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/low0cwff\" target=\"_blank\">true-brook-4</a></strong> to <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f92100411c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"BAT-baseline-hierarchical\", entity=\"frankfundel\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_mixup:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "if use_nadam:\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "scheduler = None\n",
    "if use_cosinescheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_epochs, T_mult=1)\n",
    "if use_reduceonplateu:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e066827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:47<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3179 Acc: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 53.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3843 Acc: 0.8508\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:45<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0756 Acc: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1013 Acc: 0.9702\n",
      "val_loss decreased, saving model\n",
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:46<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0501 Acc: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:01<00:00, 56.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9015 Acc: 0.7643\n",
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|██████████████████▌                                                                                                                                    | 38/310 [00:05<00:41,  6.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================== Starting at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====================\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m Acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_loss, train_acc), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, epoch, criterion, optimizer, scheduler, dataloader, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update Weights\u001b[39;00m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "    \n",
    "    val_loss, val_acc = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "    \n",
    "    if use_reduceonplateu:\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'baseline_rhinolophus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c4b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁██</td></tr><tr><td>train_loss</td><td>█▂▁</td></tr><tr><td>val_acc</td><td>▄█▁</td></tr><tr><td>val_loss</td><td>▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.98972</td></tr><tr><td>train_loss</td><td>0.05006</td></tr><tr><td>val_acc</td><td>0.76428</td></tr><tr><td>val_loss</td><td>0.90151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-brook-4</strong>: <a href=\"https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/low0cwff\" target=\"_blank\">https://wandb.ai/frankfundel/BAT-baseline-hierarchical/runs/low0cwff</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220427_161800-low0cwff/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('baseline_rhinolophus.pth'))\n",
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 'baseline_rhinolophus.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebc0662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138/138 [00:10<00:00, 13.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "corrects = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm.tqdm(test_loader):\n",
    "    output = model(inputs.cuda()) # Feed Network\n",
    "\n",
    "    output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "    Y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    Y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eef5247f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=-1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('baseline_rhinolophus_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce7f01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9605799728137744\n",
      "F1-score: 0.9606633026340764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "corrects = np.equal(Y_pred, Y_true).sum()\n",
    "print(\"Test accuracy:\", corrects/len(Y_pred))\n",
    "print(\"F1-score:\", f1_score(Y_true, Y_pred, average=None).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780ba34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
