{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce23cc9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../datasets/')\n",
    "from prepare_individuals import prepare, classes13, classes22\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = classes22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f926e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 22/22 [04:29<00:00, 12.23s/it]\n",
      "100%|███████████████████████████████████████████| 22/22 [01:59<00:00,  5.42s/it]\n",
      "100%|███████████████████████████████████████████| 22/22 [01:09<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "patch_len = 44                               # = 250ms ~ 25ms\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = prepare(\"../datasets/prepared.h5\", classes, patch_len, ml=True, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2f9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calls: 33128\n",
      "(19393, 44, 257) (19393,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total calls:\", len(X_train) + len(X_test) + len(X_val))\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0ec1c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5939c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stochdepth = True\n",
    "use_mixedprecision = False\n",
    "use_sampler = False\n",
    "use_cosinescheduler = False\n",
    "use_reduceonplateu = True\n",
    "use_nadam = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "            \n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x = torchvision.ops.stochastic_depth(input=x, p=0.25, mode='batch', training=self.training)  # randomly zero input tensor\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335a469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77040aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, scheduler, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(enabled=use_mixedprecision):\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += (predictions == labels).sum().item()\n",
    "        \n",
    "        # Perform learning rate step\n",
    "        if use_cosinescheduler:\n",
    "            scheduler.step(epoch + batch / num_batches)\n",
    "    \n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch, (inputs, labels) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update Weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (predictions == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_acc = running_corrects / num_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80eec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "warmup_epochs = 5\n",
    "wd = 0.01\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(np.expand_dims(X_train, axis=1)), torch.from_numpy(Y_train))\n",
    "test_data = TensorDataset(torch.Tensor(np.expand_dims(X_test, axis=1)), torch.from_numpy(Y_test))\n",
    "val_data = TensorDataset(torch.Tensor(np.expand_dims(X_val, axis=1)), torch.from_numpy(Y_val))\n",
    "\n",
    "if use_sampler:\n",
    "    train_loader = DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, sampler=ImbalancedDatasetSampler(test_data), batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, sampler=ImbalancedDatasetSampler(val_data), batch_size=batch_size)\n",
    "else:\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(50, Block, image_channels=1, num_classes=22)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ffundel/BAT/models/wandb/run-20220417_183934-28repz2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/frankfundel/BAT-baseline/runs/28repz2j\" target=\"_blank\">dutiful-voice-33</a></strong> to <a href=\"https://wandb.ai/frankfundel/BAT-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▍                     | 74/152 [00:35<00:37,  2.09it/s]"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"BAT-baseline\", entity=\"frankfundel\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "if use_nadam:\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "scheduler = None\n",
    "if use_cosinescheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=warmup_epochs, T_mult=1)\n",
    "if use_reduceonplateu:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "min_val_loss = np.inf\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, epoch, criterion, optimizer, scheduler, train_loader, device)\n",
    "    print('Training loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "    \n",
    "    val_loss, val_acc = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "    \n",
    "    if use_reduceonplateu:\n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'baseline.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.jit.script(model)\n",
    "torch.jit.save(compiled_model, 's0.25+r+0.1 lr+ml classes22.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in tqdm.tqdm(test_loader):\n",
    "        output = model(inputs.cuda()) # Feed Network\n",
    "        \n",
    "        output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
    "        Y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        Y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=-1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('confusion_matrix classes22.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f01b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
